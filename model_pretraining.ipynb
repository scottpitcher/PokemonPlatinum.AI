{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model PreTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Purpose: </b> Through this script, we will provide the RLHF model a starting point of knowledge on the game via training on annotated gamplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import importlib_metadata\n",
    "from google.cloud import storage\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "\n",
    "print(\"Packages imported!\")\n",
    "\n",
    "# Set the device\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "gcs_credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "\n",
    "# Initialize GCS Client\n",
    "client = storage.Client()\n",
    "print(f\"GCS Client Initialized: {client}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action mapping from strings to integers\n",
    "ACTION_MAPPING = {\n",
    "    \"a\": 0,\n",
    "    \"b\": 1,\n",
    "    \"x\": 2,\n",
    "    \"y\": 3,\n",
    "    \"up\": 4,\n",
    "    \"down\": 5,\n",
    "    \"left\": 6,\n",
    "    \"right\": 7,\n",
    "    \"none\": 8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataloader is abnormal in the sense that each data point is actually a sequence of several. <br>\n",
    "This is done to enable memory, vital for a storyline game like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokemonDatasetGCS(Dataset):\n",
    "    def __init__(self, bucket_name, states_prefix,augmentation, actions_prefix, seq_length, transform=None):\n",
    "        self.bucket = client.bucket(bucket_name)               # GCS bucket\n",
    "        self.states_prefix = states_prefix                     # Prefix for states (images) in GCS\n",
    "        self.actions_prefix = actions_prefix                   # Prefix for actions (JSONs) in GCS\n",
    "        self.transform = transform                             # Any image transformations\n",
    "        self.augmentation = augmentation                       # Any image augmentations\n",
    "\n",
    "        # Fetch the list of blobs (files) in each folder\n",
    "        self.states = sorted([blob.name for blob in self.bucket.list_blobs(prefix=states_prefix) if blob.name.endswith('.jpg')])\n",
    "        self.actions = sorted([blob.name for blob in self.bucket.list_blobs(prefix=actions_prefix) if blob.name.endswith('.json')])\n",
    "\n",
    "        self.seq_length = seq_length                           # Desired sequence length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.states) - self.seq_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        state_seq = []\n",
    "        action_seq = []\n",
    "\n",
    "        # Loop to obtain seq_length states, actions, and annotations\n",
    "        for i in range(self.seq_length):\n",
    "            # Load image from GCS with error handling\n",
    "            try:\n",
    "                state_blob = self.bucket.blob(self.states[idx + i])\n",
    "                image_data = state_blob.download_as_bytes()  # Download the image as bytes\n",
    "\n",
    "                # Wrap the byte data with BytesIO to create a file-like object\n",
    "                image = Image.open(BytesIO(image_data)).convert('RGB')  # Ensure image is in RGB format\n",
    "\n",
    "                if self.augmentation:\n",
    "                    image = self.augmentation(image)\n",
    "                \n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "\n",
    "                state_seq.append(image)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading image {self.states[idx + i]}: {e}\")\n",
    "                return None  # Skip this batch if there's an error\n",
    "            \n",
    "            # Load action JSON from GCS with error handling\n",
    "            try:\n",
    "                action_blob = self.bucket.blob(self.actions[idx + i])\n",
    "                action_data = json.loads(action_blob.download_as_text())\n",
    "                action = action_data.get('action', None)\n",
    "\n",
    "                if action is None:\n",
    "                    print(f\"Warning: 'action' key missing in {action_blob.name}\")\n",
    "                    return None  # Skip this batch if there's missing action\n",
    "                else:\n",
    "                    action_seq.append(ACTION_MAPPING[action])\n",
    "\n",
    "            except (json.JSONDecodeError, Exception) as e:\n",
    "                print(f\"Error downloading or decoding action {self.actions[idx + i]}: {e}\")\n",
    "                return None  # Skip this batch if there's an error\n",
    "\n",
    "        # Convert state sequences to tensor\n",
    "        state_seq_tensor = torch.stack(state_seq)\n",
    "\n",
    "        # Convert action sequences to tensor\n",
    "        action_seq_tensor = torch.tensor(action_seq, dtype=torch.long)\n",
    "\n",
    "        return state_seq_tensor, action_seq_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, states_dir, actions_dir, seq_length, transform=None):\n",
    "        self.states_dir = states_dir                            # Reading in the states directory\n",
    "        self.actions_dir = actions_dir                          # Reading in the actions directory\n",
    "        self.transform = transform                              # Any image transformations \n",
    "        \n",
    "        # Filter files to only include valid images\n",
    "        self.states = sorted([f for f in os.listdir(states_dir) if f.endswith('.jpg')])\n",
    "        self.actions = sorted([f for f in os.listdir(actions_dir) if f.endswith('.json')])\n",
    "\n",
    "        self.seq_length = seq_length                            # Reading in the desired seq length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states) - self.seq_length               # Returns len of dataloader\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        state_seq = []\n",
    "        action_seq = []\n",
    "\n",
    "        # Obtaining seq_length images, actions, and annotations\n",
    "        for i in range(self.seq_length):\n",
    "\n",
    "            # Retrieve image\n",
    "            img_name = os.path.join(self.states_dir, self.states[idx + i])\n",
    "            image = Image.open(img_name).convert('RGB')  # Ensure image is in RGB format\n",
    "            if self.transform:\n",
    "                image = self.transform(image) # Transform image\n",
    "            state_seq.append(image)\n",
    "\n",
    "            # Retrieve action\n",
    "            action_name = os.path.join(self.actions_dir, self.actions[idx + i])\n",
    "            ## Check if the JSON file is empty or corrupted\n",
    "            try:\n",
    "                with open(action_name, 'r') as f:\n",
    "                    if os.stat(action_name).st_size == 0:\n",
    "                        print(f\"Warning: {action_name} is empty. Skipping this file.\")\n",
    "                        action_seq.append(None)  # Skip this entry\n",
    "                        continue\n",
    "\n",
    "                    action_data = json.load(f)\n",
    "                    action = action_data.get('action', None)\n",
    "\n",
    "                    if action is None:\n",
    "                        print(f\"Warning: 'action' key missing in {action_name}\")\n",
    "                        action_seq.append(None)  # Skip this entry\n",
    "                    else:\n",
    "                        action_seq.append(ACTION_MAPPING[action])\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Warning: Failed to decode JSON in {action_name}: {e}\")\n",
    "                action_seq.append(None)  # Skip this entry\n",
    "\n",
    "        # Convert state sequences to tensor\n",
    "        state_seq_tensor = torch.stack(state_seq)\n",
    "\n",
    "        # Convert action sequences to tensor\n",
    "        action_seq_tensor = torch.tensor(action_seq, dtype=torch.long)\n",
    "\n",
    "        \n",
    "        return state_seq_tensor, action_seq_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosen transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Chosen augmentatons\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1), # Random colour augmentation\n",
    "    transforms.RandomRotation(degrees=30),                # Random rotation\n",
    "])\n",
    "\n",
    "seq_length = 3\n",
    "# Set the GCS bucket and folder prefixes\n",
    "bucket_name = 'pokemonplatinumai-annotationimages'\n",
    "states_prefix = 'phase-1/images/'\n",
    "actions_prefix = 'phase-1/actions/'\n",
    "\n",
    "dataset = PokemonDatasetGCS(\n",
    "    bucket_name=bucket_name,\n",
    "    states_prefix=states_prefix,\n",
    "    actions_prefix=actions_prefix,\n",
    "    seq_length=seq_length,\n",
    "    transform=transform,\n",
    "    augmentation = augmentation\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "print(\"DataLoader loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.PokemonModelLSTM import PokemonModelLSTM\n",
    "# Setting Hyperparameters\n",
    "num_actions = 9  # (Total Number of Actions: [A, B, X, Y, Up, Down, Left, Right, None]) (Excluding Start, Select, L, R to reduce model complexity)\n",
    "input_size = 32 * 160 * 160\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_epochs = 20\n",
    "learning_rate = 0.003\n",
    "\n",
    "# Initialising model\n",
    "model = PokemonModelLSTM(input_size, hidden_size, num_layers, num_actions).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and optimizer state if a checkpoint exists\n",
    "if os.path.exists(\"models/pokemon_model_lstm.pth\"):\n",
    "    state_dict = torch.load(\"models/pokemon_model_lstm.pth\")\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0  # Track loss for the current epoch\n",
    "    \n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Skip batches that returned None\n",
    "        if batch is None:\n",
    "            print(f\"Skipping batch {i} due to missing data.\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Processing epoch {epoch}, batch {i}\")\n",
    "        \n",
    "        state_seq, action_seq = batch\n",
    "        state_seq, action_seq = state_seq.to(device), action_seq.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(state_seq)\n",
    "\n",
    "        # Calculate loss\n",
    "        action_seq = action_seq[:, -1]  # Get the last action in the sequence for each batch\n",
    "        loss = criterion(output, action_seq)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss for the epoch\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Log loss for the epoch\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
    "\n",
    "    \n",
    "    # Save the model, optimizer state, and other information after each epoch\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss.item(),\n",
    "    }\n",
    "    model_path = f\"models/phase1/pokemon_model_lstm_epoch_{epoch+1}.pth\"\n",
    "    torch.save(checkpoint, model_path)\n",
    "\n",
    "# Save final model with all relevant states\n",
    "final_checkpoint = {\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss.item(),\n",
    "    }\n",
    "\n",
    "final_model_path = \"models/pokemon_model_lstm_final.pth\"\n",
    "torch.save(final_checkpoint, final_model_path)\n",
    "\n",
    "print(\"Model and metrics logged with MLflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from RLHF_Scripts.modular_scripts.rlhf_utils import ACTION_MAP_DIALOGUE, REVERSED_ACTION_MAPPING\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "gcs_credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "\n",
    "# Initialize GCS Client\n",
    "client = storage.Client()\n",
    "print(f\"GCS Client Initialized: {client}\")\n",
    "\n",
    "# Define the GCS bucket and file path\n",
    "bucket_name = 'pokemonplatinumai-annotationimages'\n",
    "file_path = 'phase-1/images/2024-09-01_21-41-17_png.rf.8afcea2c3ddb01cfa1caa95e8777b066.jpg'\n",
    "\n",
    "# Preprocess the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640,640)),  # Resize image\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "])\n",
    "\n",
    "# Initialize GCS client and get the image file\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "blob = bucket.blob(file_path)\n",
    "\n",
    "# Download the image as a byte stream and open it\n",
    "image_data = blob.download_as_bytes()\n",
    "image = Image.open(BytesIO(image_data))\n",
    "\n",
    "# Apply transformations\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0).unsqueeze(0)  # Add batch dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.PokemonModelLSTM import PokemonModelLSTM\n",
    "\n",
    "# Setting Hyperparameters\n",
    "num_actions = 9  # Total number of actions\n",
    "input_size = 32 * 160 * 160\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize model\n",
    "model = PokemonModelLSTM(input_size, hidden_size, num_layers, num_actions)\n",
    "checkpoint = torch.load(\"models/phase1/pokemon_model_lstm_epoch_5.pth\", map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "print('Model loaded')\n",
    "\n",
    "# Perform prediction\n",
    "with torch.no_grad():  # Disable gradient calculations for inference\n",
    "    action = model(image)  # Pass the image through the model\n",
    "    predicted_action = torch.argmax(action, dim=1)  # Get the predicted action\n",
    "\n",
    "action = ACTION_MAP_DIALOGUE[REVERSED_ACTION_MAPPING[predicted_action.item()]]\n",
    "print(f'Prediction made: {action}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MLflow experiment\n",
    "mlflow.set_experiment(\"PokemonModelLSTM_3\")\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"num_actions\", num_actions)\n",
    "    mlflow.log_param(\"input_size\", input_size)\n",
    "    mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "    mlflow.log_param(\"num_layers\", num_layers)\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    " \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0                       # Track loss for the current epoch\n",
    "        for i, (state_seq, action_seq) in enumerate(dataloader):\n",
    "            print(f\"Currently processing Epoch {epoch}, batch {i}\")\n",
    "            state_seq, action_seq = state_seq.to(device), action_seq.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(state_seq)\n",
    "\n",
    "            # Calculate loss\n",
    "            action_seq = action_seq[:, -1]  # Get the last action in the sequence for each batch\n",
    "            loss = criterion(output, action_seq)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss for the epoch\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        # Save the model to MLflow\n",
    "        print(f\"Saving model to MLflow\")\n",
    "        mlflow.pytorch.log_model(model, f\"model_epoch_{epoch+1}\")\n",
    "\n",
    "        # Log loss for the epoch\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        try: \n",
    "            mlflow.log_metric(\"loss\", avg_loss, step=epoch)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
    "        \n",
    "        # Save the model, optimizer state, and other information after each epoch\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "        }\n",
    "        model_path = f\"models/pokemon_model_lstm_epoch_{epoch+1}.pth\"\n",
    "        torch.save(checkpoint, model_path)\n",
    "\n",
    "    # Save final model with all relevant states\n",
    "    final_checkpoint = {\n",
    "        'epoch': num_epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss.item(),\n",
    "        }\n",
    "    \n",
    "    final_model_path = \"models/pokemon_model_lstm_final.pth\"\n",
    "    torch.save(final_checkpoint, final_model_path)\n",
    "    mlflow.pytorch.log_model(model, \"final_model\")\n",
    "\n",
    "print(\"Model and metrics logged with MLflow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple test model (or use your existing model)\n",
    "class TestModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(10, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = TestModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Test the logging step without running the full training loop\n",
    "def test_mlflow_logging():\n",
    "    with mlflow.start_run():\n",
    "        # Create a dummy state dict and loss for testing purposes\n",
    "        test_checkpoint = {\n",
    "            'epoch': 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': 0.5,  # Dummy loss value\n",
    "        }\n",
    "\n",
    "        # Save and log the model using MLflow\n",
    "        model_path = \"models/test_model.pth\"\n",
    "        torch.save(test_checkpoint, model_path)\n",
    "\n",
    "        try:\n",
    "            # Test logging the model with MLflow\n",
    "            mlflow.pytorch.log_model(model, \"test_model\")\n",
    "            print(\"MLflow model logging successful.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during MLflow logging: {e}\")\n",
    "\n",
    "# Run the test function\n",
    "test_mlflow_logging()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_versions():\n",
    "    try:\n",
    "        # Check torch version using importlib_metadata\n",
    "        torch_version = importlib_metadata.version(\"torch\")\n",
    "        print(f\"importlib_metadata found torch version: {torch_version}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Could not find version for 'torch': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error occurred: {e}\")\n",
    "\n",
    "    # Also check torch version from the package itself\n",
    "    print(f\"torch.__version__: {torch.__version__}\")\n",
    "\n",
    "    try:\n",
    "        # Simulate a log model call with MLflow to verify functionality\n",
    "        model = torch.nn.Linear(2, 2)  # Create a simple dummy model for testing\n",
    "        mlflow.set_tracking_uri(\"mlruns\")\n",
    "        mlflow.set_experiment(\"VerificationExperiment\")\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.pytorch.log_model(\n",
    "                model, \n",
    "                artifact_path=\"dummy_model\",\n",
    "                pip_requirements=[f\"torch=={torch.__version__}\", \"cloudpickle==2.0.0\"]\n",
    "            )\n",
    "            print(\"MLflow logging successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"MLflow encountered an error: {e}\")\n",
    "\n",
    "# Run the verification\n",
    "check_versions()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
