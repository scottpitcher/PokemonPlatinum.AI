{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model PreTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Purpose: </b> Through this script, we will provide the RLHF model a starting point of knowledge on the game via training on annotated gamplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages imported!\n",
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottpitcher/Desktop/python/Github/PokemonPlatinum.AI/.venv/lib/python3.10/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/scottpitcher/Desktop/python/Github/PokemonPlatinum.AI/model_pretraining.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/scottpitcher/Desktop/python/Github/PokemonPlatinum.AI/model_pretraining.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m gcs_credentials_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mGOOGLE_APPLICATION_CREDENTIALS\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/scottpitcher/Desktop/python/Github/PokemonPlatinum.AI/model_pretraining.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Initialize GCS Client\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/scottpitcher/Desktop/python/Github/PokemonPlatinum.AI/model_pretraining.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m client \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49mClient()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/scottpitcher/Desktop/python/Github/PokemonPlatinum.AI/model_pretraining.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGCS Client Initialized: \u001b[39m\u001b[39m{\u001b[39;00mclient\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/python/Github/PokemonPlatinum.AI/.venv/lib/python3.10/site-packages/google/cloud/storage/client.py:227\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, project, credentials, _http, client_info, client_options, use_auth_w_custom_endpoint, extra_headers)\u001b[0m\n\u001b[1;32m    224\u001b[0m             no_project \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    225\u001b[0m             project \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<none>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 227\u001b[0m \u001b[39msuper\u001b[39;49m(Client, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    228\u001b[0m     project\u001b[39m=\u001b[39;49mproject,\n\u001b[1;32m    229\u001b[0m     credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[1;32m    230\u001b[0m     client_options\u001b[39m=\u001b[39;49mclient_options,\n\u001b[1;32m    231\u001b[0m     _http\u001b[39m=\u001b[39;49m_http,\n\u001b[1;32m    232\u001b[0m )\n\u001b[1;32m    234\u001b[0m \u001b[39m# Validate that the universe domain of the credentials matches the\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m# universe domain of the client.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_credentials\u001b[39m.\u001b[39muniverse_domain \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muniverse_domain:\n",
      "File \u001b[0;32m~/Desktop/python/Github/PokemonPlatinum.AI/.venv/lib/python3.10/site-packages/google/cloud/client/__init__.py:320\u001b[0m, in \u001b[0;36mClientWithProject.__init__\u001b[0;34m(self, project, credentials, client_options, _http)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, project\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, credentials\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, client_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _http\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 320\u001b[0m     _ClientProjectMixin\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, project\u001b[39m=\u001b[39;49mproject, credentials\u001b[39m=\u001b[39;49mcredentials)\n\u001b[1;32m    321\u001b[0m     Client\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    322\u001b[0m         \u001b[39mself\u001b[39m, credentials\u001b[39m=\u001b[39mcredentials, client_options\u001b[39m=\u001b[39mclient_options, _http\u001b[39m=\u001b[39m_http\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/python/Github/PokemonPlatinum.AI/.venv/lib/python3.10/site-packages/google/cloud/client/__init__.py:268\u001b[0m, in \u001b[0;36m_ClientProjectMixin.__init__\u001b[0;34m(self, project, credentials)\u001b[0m\n\u001b[1;32m    265\u001b[0m     project \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(credentials, \u001b[39m\"\u001b[39m\u001b[39mproject_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    267\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     project \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_determine_default(project)\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    272\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mProject was not passed and could not be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdetermined from the environment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/python/Github/PokemonPlatinum.AI/.venv/lib/python3.10/site-packages/google/cloud/client/__init__.py:287\u001b[0m, in \u001b[0;36m_ClientProjectMixin._determine_default\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_determine_default\u001b[39m(project):\n\u001b[1;32m    286\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Helper:  use default project detection.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[39mreturn\u001b[39;00m _determine_default_project(project)\n",
      "File \u001b[0;32m~/Desktop/python/Github/PokemonPlatinum.AI/.venv/lib/python3.10/site-packages/google/cloud/_helpers/__init__.py:152\u001b[0m, in \u001b[0;36m_determine_default_project\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Determine default project ID explicitly or implicitly as fall-back.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[39mSee :func:`google.auth.default` for details on how the default project\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39m:returns: Default project if it can be determined.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     _, project \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39;49mauth\u001b[39m.\u001b[39;49mdefault()\n\u001b[1;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m project\n",
      "File \u001b[0;32m~/Desktop/python/Github/PokemonPlatinum.AI/.venv/lib/python3.10/site-packages/google/auth/_default.py:657\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    645\u001b[0m checkers \u001b[39m=\u001b[39m (\n\u001b[1;32m    646\u001b[0m     \u001b[39m# Avoid passing scopes here to prevent passing scopes to user credentials.\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     \u001b[39m# with_scopes_if_required() below will ensure scopes/default scopes are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_gce_credentials(request, quota_project_id\u001b[39m=\u001b[39mquota_project_id),\n\u001b[1;32m    654\u001b[0m )\n\u001b[1;32m    656\u001b[0m \u001b[39mfor\u001b[39;00m checker \u001b[39min\u001b[39;00m checkers:\n\u001b[0;32m--> 657\u001b[0m     credentials, project_id \u001b[39m=\u001b[39m checker()\n\u001b[1;32m    658\u001b[0m     \u001b[39mif\u001b[39;00m credentials \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    659\u001b[0m         credentials \u001b[39m=\u001b[39m with_scopes_if_required(\n\u001b[1;32m    660\u001b[0m             credentials, scopes, default_scopes\u001b[39m=\u001b[39mdefault_scopes\n\u001b[1;32m    661\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/python/Github/PokemonPlatinum.AI/.venv/lib/python3.10/site-packages/google/auth/_default.py:651\u001b[0m, in \u001b[0;36mdefault.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauth\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcredentials\u001b[39;00m \u001b[39mimport\u001b[39;00m CredentialsWithQuotaProject\n\u001b[1;32m    641\u001b[0m explicit_project_id \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\n\u001b[1;32m    642\u001b[0m     environment_vars\u001b[39m.\u001b[39mPROJECT, os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(environment_vars\u001b[39m.\u001b[39mLEGACY_PROJECT)\n\u001b[1;32m    643\u001b[0m )\n\u001b[1;32m    645\u001b[0m checkers \u001b[39m=\u001b[39m (\n\u001b[1;32m    646\u001b[0m     \u001b[39m# Avoid passing scopes here to prevent passing scopes to user credentials.\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     \u001b[39m# with_scopes_if_required() below will ensure scopes/default scopes are\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     \u001b[39m# safely set on the returned credentials since requires_scopes will\u001b[39;00m\n\u001b[1;32m    649\u001b[0m     \u001b[39m# guard against setting scopes on user credentials.\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_explicit_environ_credentials(quota_project_id\u001b[39m=\u001b[39mquota_project_id),\n\u001b[0;32m--> 651\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_gcloud_sdk_credentials(quota_project_id\u001b[39m=\u001b[39;49mquota_project_id),\n\u001b[1;32m    652\u001b[0m     _get_gae_credentials,\n\u001b[1;32m    653\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_gce_credentials(request, quota_project_id\u001b[39m=\u001b[39mquota_project_id),\n\u001b[1;32m    654\u001b[0m )\n\u001b[1;32m    656\u001b[0m \u001b[39mfor\u001b[39;00m checker \u001b[39min\u001b[39;00m checkers:\n\u001b[1;32m    657\u001b[0m     credentials, project_id \u001b[39m=\u001b[39m checker()\n",
      "File \u001b[0;32m~/Desktop/python/Github/PokemonPlatinum.AI/.venv/lib/python3.10/site-packages/google/auth/_default.py:242\u001b[0m, in \u001b[0;36m_get_gcloud_sdk_credentials\u001b[0;34m(quota_project_id)\u001b[0m\n\u001b[1;32m    237\u001b[0m credentials, project_id \u001b[39m=\u001b[39m load_credentials_from_file(\n\u001b[1;32m    238\u001b[0m     credentials_filename, quota_project_id\u001b[39m=\u001b[39mquota_project_id\n\u001b[1;32m    239\u001b[0m )\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m project_id:\n\u001b[0;32m--> 242\u001b[0m     project_id \u001b[39m=\u001b[39m _cloud_sdk\u001b[39m.\u001b[39;49mget_project_id()\n\u001b[1;32m    244\u001b[0m \u001b[39mreturn\u001b[39;00m credentials, project_id\n",
      "File \u001b[0;32m~/Desktop/python/Github/PokemonPlatinum.AI/.venv/lib/python3.10/site-packages/google/auth/_cloud_sdk.py:106\u001b[0m, in \u001b[0;36mget_project_id\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m     command \u001b[39m=\u001b[39m _CLOUD_SDK_POSIX_COMMAND\n\u001b[1;32m    103\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[39m# Ignore the stderr coming from gcloud, so it won't be mixed into the output.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[39m# https://github.com/googleapis/google-auth-library-python/issues/673\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     project \u001b[39m=\u001b[39m _run_subprocess_ignore_stderr(\n\u001b[1;32m    107\u001b[0m         (command,) \u001b[39m+\u001b[39;49m _CLOUD_SDK_CONFIG_GET_PROJECT_COMMAND\n\u001b[1;32m    108\u001b[0m     )\n\u001b[1;32m    110\u001b[0m     \u001b[39m# Turn bytes into a string and remove \"\\n\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     project \u001b[39m=\u001b[39m _helpers\u001b[39m.\u001b[39mfrom_bytes(project)\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/Desktop/python/Github/PokemonPlatinum.AI/.venv/lib/python3.10/site-packages/google/auth/_cloud_sdk.py:88\u001b[0m, in \u001b[0;36m_run_subprocess_ignore_stderr\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Return subprocess.check_output with the given command and ignores stderr.\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mdevnull, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m devnull:\n\u001b[0;32m---> 88\u001b[0m     output \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mcheck_output(command, stderr\u001b[39m=\u001b[39;49mdevnull)\n\u001b[1;32m     89\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py:421\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m         empty \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    419\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m empty\n\u001b[0;32m--> 421\u001b[0m \u001b[39mreturn\u001b[39;00m run(\u001b[39m*\u001b[39;49mpopenargs, stdout\u001b[39m=\u001b[39;49mPIPE, timeout\u001b[39m=\u001b[39;49mtimeout, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    422\u001b[0m            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39;49mcommunicate(\u001b[39minput\u001b[39;49m, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    506\u001b[0m     \u001b[39mexcept\u001b[39;00m TimeoutExpired \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[39m.\u001b[39mkill()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py:1141\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stdin_write(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1140\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout:\n\u001b[0;32m-> 1141\u001b[0m     stdout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m   1142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1143\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import importlib_metadata\n",
    "from google.cloud import storage\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "\n",
    "print(\"Packages imported!\")\n",
    "\n",
    "# Set the device\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "gcs_credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "\n",
    "# Initialize GCS Client\n",
    "client = storage.Client()\n",
    "print(f\"GCS Client Initialized: {client}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action mapping from strings to integers\n",
    "ACTION_MAPPING = {\n",
    "    \"a\": 0,\n",
    "    \"b\": 1,\n",
    "    \"x\": 2,\n",
    "    \"y\": 3,\n",
    "    \"up\": 4,\n",
    "    \"down\": 5,\n",
    "    \"left\": 6,\n",
    "    \"right\": 7,\n",
    "    \"none\": 8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataloader is abnormal in the sense that each data point is actually a sequence of several. <br>\n",
    "This is done to enable memory, vital for a storyline game like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokemonDatasetGCS(Dataset):\n",
    "    def __init__(self, bucket_name, states_prefix, actions_prefix, annotations_prefix, seq_length, transform=None):\n",
    "        self.bucket = client.bucket(bucket_name)               # GCS bucket\n",
    "        self.states_prefix = states_prefix                     # Prefix for states (images) in GCS\n",
    "        self.actions_prefix = actions_prefix                   # Prefix for actions (JSONs) in GCS\n",
    "        self.annotations_prefix = annotations_prefix           # Prefix for annotations (texts) in GCS\n",
    "        self.transform = transform                             # Any image transformations\n",
    "        \n",
    "        # Fetch the list of blobs (files) in each folder\n",
    "        self.states = sorted([blob.name for blob in self.bucket.list_blobs(prefix=states_prefix) if blob.name.endswith('.jpg')])\n",
    "        self.actions = sorted([blob.name for blob in self.bucket.list_blobs(prefix=actions_prefix) if blob.name.endswith('.json')])\n",
    "        self.annotations = sorted([blob.name for blob in self.bucket.list_blobs(prefix=annotations_prefix) if blob.name.endswith('.txt')])\n",
    "\n",
    "        self.seq_length = seq_length                           # Desired sequence length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.states) - self.seq_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        state_seq = []\n",
    "        action_seq = []\n",
    "        annotation_seq = []\n",
    "\n",
    "        # Loop to obtain seq_length states, actions, and annotations\n",
    "        for i in range(self.seq_length):\n",
    "            # Load image from GCS\n",
    "            state_blob = self.bucket.blob(self.states[idx + i])\n",
    "            image_data = state_blob.download_as_bytes()  # Download the image as bytes\n",
    "            \n",
    "            # Wrap the byte data with BytesIO to create a file-like object\n",
    "            image = Image.open(BytesIO(image_data)).convert('RGB')  # Ensure image is in RGB format\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            state_seq.append(image)\n",
    "\n",
    "            # Load action JSON from GCS\n",
    "            action_blob = self.bucket.blob(self.actions[idx + i])\n",
    "            try:\n",
    "                action_data = json.loads(action_blob.download_as_text())\n",
    "                action = action_data.get('action', None)\n",
    "\n",
    "                if action is None:\n",
    "                    print(f\"Warning: 'action' key missing in {action_blob.name}\")\n",
    "                    action_seq.append(None)  # Skip this entry\n",
    "                else:\n",
    "                    action_seq.append(ACTION_MAPPING[action])\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Warning: Failed to decode JSON in {action_blob.name}: {e}\")\n",
    "                action_seq.append(None)  # Skip this entry\n",
    "\n",
    "            # Load annotation file from GCS\n",
    "            annotation_blob = self.bucket.blob(self.annotations[idx + i])\n",
    "            annotation_data = annotation_blob.download_as_text()\n",
    "            annotations = [list(map(float, line.strip().split())) for line in annotation_data.splitlines()]  # Ensure annotations are list of floats\n",
    "            annotation_seq.append(annotations)\n",
    "\n",
    "        # Convert state sequences to tensor\n",
    "        state_seq_tensor = torch.stack(state_seq)\n",
    "\n",
    "        # Convert action sequences to tensor\n",
    "        action_seq_tensor = torch.tensor(action_seq, dtype=torch.long)\n",
    "\n",
    "        # Pad annotations to a fixed size and convert to tensor\n",
    "        max_annotations = 25\n",
    "        padded_annotations = []\n",
    "        for ann in annotation_seq:\n",
    "            if len(ann) < max_annotations:\n",
    "                ann += [[-1, 0, 0, 0, 0]] * (max_annotations - len(ann))\n",
    "            elif len(ann) > max_annotations:\n",
    "                ann = ann[:max_annotations]\n",
    "            padded_annotations.append(ann)\n",
    "        annotation_seq_tensor = torch.tensor(padded_annotations, dtype=torch.float32)\n",
    "\n",
    "        return state_seq_tensor, action_seq_tensor, annotation_seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, states_dir, actions_dir, annotations_dir, seq_length, transform=None):\n",
    "        self.states_dir = states_dir                            # Reading in the states directory\n",
    "        self.actions_dir = actions_dir                          # Reading in the actions directory\n",
    "        self.annotations_dir = annotations_dir                  # Reading in the annotations directory\n",
    "        self.transform = transform                              # Any image transformations \n",
    "        \n",
    "        # Filter files to only include valid images\n",
    "        self.states = sorted([f for f in os.listdir(states_dir) if f.endswith('.jpg')])\n",
    "        self.actions = sorted([f for f in os.listdir(actions_dir) if f.endswith('.json')])\n",
    "        self.annotations = sorted([f for f in os.listdir(annotations_dir) if f.endswith('.txt')])\n",
    "\n",
    "        self.seq_length = seq_length                            # Reading in the desired seq length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states) - self.seq_length               # Returns len of dataloader\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        state_seq = []\n",
    "        action_seq = []\n",
    "        annotation_seq = []\n",
    "\n",
    "        # Obtaining seq_length images, actions, and annotations\n",
    "        for i in range(self.seq_length):\n",
    "\n",
    "            # Retrieve image\n",
    "            img_name = os.path.join(self.states_dir, self.states[idx + i])\n",
    "            image = Image.open(img_name).convert('RGB')  # Ensure image is in RGB format\n",
    "            if self.transform:\n",
    "                image = self.transform(image) # Transform image\n",
    "            state_seq.append(image)\n",
    "\n",
    "            # Retrieve action\n",
    "            action_name = os.path.join(self.actions_dir, self.actions[idx + i])\n",
    "            ## Check if the JSON file is empty or corrupted\n",
    "            try:\n",
    "                with open(action_name, 'r') as f:\n",
    "                    if os.stat(action_name).st_size == 0:\n",
    "                        print(f\"Warning: {action_name} is empty. Skipping this file.\")\n",
    "                        action_seq.append(None)  # Skip this entry\n",
    "                        continue\n",
    "\n",
    "                    action_data = json.load(f)\n",
    "                    action = action_data.get('action', None)\n",
    "\n",
    "                    if action is None:\n",
    "                        print(f\"Warning: 'action' key missing in {action_name}\")\n",
    "                        action_seq.append(None)  # Skip this entry\n",
    "                    else:\n",
    "                        action_seq.append(ACTION_MAPPING[action])\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Warning: Failed to decode JSON in {action_name}: {e}\")\n",
    "                action_seq.append(None)  # Skip this entry\n",
    "\n",
    "\n",
    "            #Retrieve Annotation\n",
    "            annotation_name = os.path.join(self.annotations_dir, self.annotations[idx + i].replace('.jpg', '.txt'))\n",
    "            with open(annotation_name, 'r') as f:\n",
    "                annotations = [list(map(float, line.strip().split())) for line in f] # Ensure annotation is list of floats\n",
    "                annotation_seq.append(annotations)\n",
    "\n",
    "        # Convert state sequences to tensor\n",
    "        state_seq_tensor = torch.stack(state_seq)\n",
    "\n",
    "        # Convert action sequences to tensor\n",
    "        action_seq_tensor = torch.tensor(action_seq, dtype=torch.long)\n",
    "\n",
    "        max_annotations = 25\n",
    "        padded_annotations = []\n",
    "        for ann in annotation_seq:\n",
    "            if len(ann) < max_annotations:\n",
    "                ann += [[-1, 0, 0, 0, 0]] * (max_annotations - len(ann))\n",
    "            elif len(ann) > max_annotations:\n",
    "                ann = ann[:max_annotations]\n",
    "            padded_annotations.append(ann)\n",
    "        annotation_seq_tensor = torch.tensor(padded_annotations, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        return state_seq_tensor, action_seq_tensor, annotation_seq_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosen transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "seq_length = 3\n",
    "# Set the GCS bucket and folder prefixes\n",
    "bucket_name = 'pokemonplatinumai-annotationimages'\n",
    "states_prefix = 'images/'\n",
    "actions_prefix = 'actions/'\n",
    "annotations_prefix = 'labels/'\n",
    "\n",
    "dataset = PokemonDatasetGCS(\n",
    "    bucket_name=bucket_name,\n",
    "    states_prefix=states_prefix,\n",
    "    actions_prefix=actions_prefix,\n",
    "    annotations_prefix=annotations_prefix,\n",
    "    seq_length=seq_length,\n",
    "    transform=transform\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "print(\"DataLoader loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring the files in the dataloader are processed properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the dataloader and check if images and actions are valid\n",
    "for i, (state_seq, action_seq, annotation_seq) in enumerate(dataloader):\n",
    "    try:\n",
    "        # Move tensors to device\n",
    "        state_seq, action_seq, annotation_seq = state_seq.to(device), action_seq.to(device), annotation_seq.to(device)\n",
    "        print(f\"Processing batch {i}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i}: {e}\")\n",
    "\n",
    "    # Check the JSON action files using the GCS blobs instead of local paths\n",
    "    for idx, action in enumerate(action_seq):\n",
    "        action_file_name = dataset.actions[i + idx]  # Retrieve the actual GCS file name\n",
    "        action_blob = dataset.bucket.blob(action_file_name)  # Get the blob from GCS\n",
    "\n",
    "        try:\n",
    "            # Check if the action file is empty\n",
    "            action_content = action_blob.download_as_text()  # Download the content as text\n",
    "            if not action_content:\n",
    "                raise ValueError(f\"Action file {action_file_name} is empty.\")\n",
    "\n",
    "            # Parse the JSON content\n",
    "            action_data = json.loads(action_content)\n",
    "            \n",
    "            # Ensure 'action' is in the JSON\n",
    "            if 'action' not in action_data:\n",
    "                raise KeyError(f\"Key 'action' missing in {action_file_name}\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Invalid JSON format in file: {action_file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {action_file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.PokemonModelLSTM import PokemonModelLSTM\n",
    "# Setting Hyperparameters\n",
    "num_actions = 9  # (Total Number of Actions: [A, B, X, Y, Up, Down, Left, Right, None]) (Excluding Start, Select, L, R to reduce model complexity)\n",
    "input_size = 32 * 160 * 160\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialising model\n",
    "model = PokemonModelLSTM(input_size, hidden_size, num_layers, num_actions).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and optimizer state if a checkpoint exists\n",
    "if os.path.exists(\"models/pokemon_model_lstm.pth\"):\n",
    "    state_dict = torch.load(\"models/pokemon_model_lstm.pth\")\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MLflow experiment\n",
    "mlflow.set_experiment(\"PokemonModelLSTM_Pretrain_3\")\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"num_actions\", num_actions)\n",
    "    mlflow.log_param(\"input_size\", input_size)\n",
    "    mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "    mlflow.log_param(\"num_layers\", num_layers)\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    " \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0                       # Track loss for the current epoch\n",
    "        for i, (state_seq, action_seq, annotation_seq) in enumerate(dataloader):\n",
    "            print(f\"Currently processing Epoch {epoch}, batch {i}\")\n",
    "            state_seq, action_seq, annotation_seq = state_seq.to(device), action_seq.to(device), annotation_seq.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(state_seq, annotations=annotation_seq)\n",
    "\n",
    "            # Calculate loss\n",
    "            action_seq = action_seq[:, -1]  # Get the last action in the sequence for each batch\n",
    "            loss = criterion(output, action_seq)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss for the epoch\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        # Save the model to MLflow\n",
    "        print(f\"Saving model to MLflow\")\n",
    "        mlflow.pytorch.log_model(model, f\"model_epoch_{epoch+1}\")\n",
    "\n",
    "        # Log loss for the epoch\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        mlflow.log_metric(\"loss\", avg_loss, step=epoch)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss}\")\n",
    "        \n",
    "        # Save the model, optimizer state, and other information after each epoch\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "        }\n",
    "        model_path = f\"models/pokemon_model_lstm_epoch_{epoch+1}.pth\"\n",
    "        torch.save(checkpoint, model_path)\n",
    "\n",
    "    # Save final model with all relevant states\n",
    "    final_checkpoint = {\n",
    "        'epoch': num_epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss.item(),\n",
    "        }\n",
    "    \n",
    "    final_model_path = \"models/pokemon_model_lstm_final.pth\"\n",
    "    torch.save(final_checkpoint, final_model_path)\n",
    "    mlflow.pytorch.log_model(model, \"final_model\")\n",
    "\n",
    "print(\"Model and metrics logged with MLflow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# Create a simple test model (or use your existing model)\n",
    "class TestModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(10, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = TestModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Test the logging step without running the full training loop\n",
    "def test_mlflow_logging():\n",
    "    with mlflow.start_run():\n",
    "        # Create a dummy state dict and loss for testing purposes\n",
    "        test_checkpoint = {\n",
    "            'epoch': 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': 0.5,  # Dummy loss value\n",
    "        }\n",
    "\n",
    "        # Save and log the model using MLflow\n",
    "        model_path = \"models/test_model.pth\"\n",
    "        torch.save(test_checkpoint, model_path)\n",
    "\n",
    "        try:\n",
    "            # Test logging the model with MLflow\n",
    "            mlflow.pytorch.log_model(model, \"test_model\")\n",
    "            print(\"MLflow model logging successful.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during MLflow logging: {e}\")\n",
    "\n",
    "# Run the test function\n",
    "test_mlflow_logging()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_versions():\n",
    "    try:\n",
    "        # Check torch version using importlib_metadata\n",
    "        torch_version = importlib_metadata.version(\"torch\")\n",
    "        print(f\"importlib_metadata found torch version: {torch_version}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Could not find version for 'torch': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error occurred: {e}\")\n",
    "\n",
    "    # Also check torch version from the package itself\n",
    "    print(f\"torch.__version__: {torch.__version__}\")\n",
    "\n",
    "    try:\n",
    "        # Simulate a log model call with MLflow to verify functionality\n",
    "        model = torch.nn.Linear(2, 2)  # Create a simple dummy model for testing\n",
    "        mlflow.set_tracking_uri(\"mlruns\")\n",
    "        mlflow.set_experiment(\"VerificationExperiment\")\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.pytorch.log_model(\n",
    "                model, \n",
    "                artifact_path=\"dummy_model\",\n",
    "                pip_requirements=[f\"torch=={torch.__version__}\", \"cloudpickle==2.0.0\"]\n",
    "            )\n",
    "            print(\"MLflow logging successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"MLflow encountered an error: {e}\")\n",
    "\n",
    "# Run the verification\n",
    "check_versions()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
